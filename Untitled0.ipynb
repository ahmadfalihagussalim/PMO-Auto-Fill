{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Otomatisasi Pengisian FORM_ID (V7.5: FULL LOG + ANTI-SKIP)\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "\n",
        "# Cek lingkungan\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Cek library thefuzz\n",
        "try:\n",
        "    from thefuzz import process, fuzz\n",
        "except ImportError:\n",
        "    print(\"Module 'thefuzz' not found. Installing...\")\n",
        "    import subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"thefuzz[speedup]\"])\n",
        "    from thefuzz import process, fuzz\n",
        "\n",
        "# --- UTILS ---\n",
        "def preprocess_text(text):\n",
        "    if pd.isna(text): return \"\"\n",
        "    text = str(text).lower().strip()\n",
        "    text = re.sub(r'[^\\w\\s\\-\\\"\\./]', ' ', text)\n",
        "    if '>' in text:\n",
        "        parts = text.split('>')\n",
        "        last = parts[-1].strip()\n",
        "        if len(last) < 3 and len(parts) > 1:\n",
        "            text = parts[-2].strip() + \" \" + last\n",
        "        else:\n",
        "            text = last\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def get_common_words_count(text1, text2, min_len=3):\n",
        "    words1 = set([w for w in text1.split() if len(w) >= min_len])\n",
        "    words2 = set([w for w in text2.split() if len(w) >= min_len])\n",
        "    return len(words1.intersection(words2))\n",
        "\n",
        "def fill_missing_form_id_v7_final():\n",
        "    # --- 1. LOAD DATA ---\n",
        "    input_file = '2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx'\n",
        "    output_filename = 'Hasil_Mapping_INTELLIGENT_FALLBACK.xlsx'\n",
        "\n",
        "    # Logika Load File\n",
        "    if not os.path.exists(input_file):\n",
        "        input_file = '2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx'\n",
        "\n",
        "    if not os.path.exists(input_file) and IN_COLAB:\n",
        "        print(\"‚ùå File input tidak ada. Upload file terakhir.\")\n",
        "        uploaded = files.upload()\n",
        "        if uploaded: input_file = list(uploaded.keys())[0]\n",
        "        else: return\n",
        "    elif not os.path.exists(input_file):\n",
        "        print(f\"‚ùå File '{input_file}' tidak ditemukan.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüì• Membaca Target dari: {input_file}\")\n",
        "    xls_target = pd.ExcelFile(input_file, engine='openpyxl')\n",
        "\n",
        "    try:\n",
        "        df_target = pd.read_excel(xls_target, sheet_name='ItemTambahanKontarPayung')\n",
        "    except:\n",
        "        df_target = pd.read_excel(xls_target, sheet_name=0)\n",
        "\n",
        "    # Load Referensi\n",
        "    ori_file = '2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx'\n",
        "    if os.path.exists(ori_file):\n",
        "        try: df_ref = pd.read_excel(ori_file, sheet_name='ItemKontrakPayung')\n",
        "        except: df_ref = pd.read_excel(ori_file, sheet_name=1)\n",
        "    elif IN_COLAB:\n",
        "        print(\"‚ö†Ô∏è Upload File Asli untuk Referensi!\")\n",
        "        uploaded = files.upload()\n",
        "        fn = list(uploaded.keys())[0]\n",
        "        df_ref = pd.read_excel(fn, sheet_name='ItemKontrakPayung')\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è File referensi '{ori_file}' tidak ditemukan.\")\n",
        "        return\n",
        "\n",
        "    # Tambah Kolom Audit\n",
        "    audit_cols = ['CONFIDENCE_LEVEL', 'MATCH_SCORE', 'MATCH_REASON', 'SARAN_NAMA_ITEM']\n",
        "    for col in audit_cols:\n",
        "        if col not in df_target.columns: df_target[col] = \"\"\n",
        "\n",
        "    # --- 2. CLEANING REFERENCE & LOGGING ---\n",
        "    print(\"\\nüßπ Membersihkan Data Referensi...\")\n",
        "    initial_len = len(df_ref)\n",
        "    df_ref['clean_key'] = df_ref['ItemPekerjaan'].apply(preprocess_text)\n",
        "\n",
        "    # Deteksi Duplikat\n",
        "    dup_mask = df_ref.duplicated(subset=['clean_key'], keep='first')\n",
        "    removed_items = df_ref[dup_mask].copy()\n",
        "\n",
        "    # Hapus Duplikat\n",
        "    df_ref_unique = df_ref.drop_duplicates(subset=['clean_key'], keep='first')\n",
        "\n",
        "    final_len = len(df_ref_unique)\n",
        "    removed_count = initial_len - final_len\n",
        "\n",
        "    print(f\"   - Awal: {initial_len} baris\")\n",
        "    print(f\"   - Duplikat Dihapus: {removed_count} baris\")\n",
        "\n",
        "    if removed_count > 0:\n",
        "        print(\"\\nüìã DAFTAR LENGKAP ITEM YANG DIHAPUS (DUPLIKAT):\")\n",
        "        print(\"=\" * 110)\n",
        "        print(f\"{'NAMA ITEM':<60} | {'ID DIBUANG':<20} | {'ID DIPAKAI':<20}\")\n",
        "        print(\"=\" * 110)\n",
        "\n",
        "        kept_map = df_ref_unique.set_index('clean_key')['FORM_ID_KONTRAK_PAYUNG'].to_dict()\n",
        "        item_list = removed_items[['ItemPekerjaan', 'FORM_ID_KONTRAK_PAYUNG', 'clean_key']].values.tolist()\n",
        "\n",
        "        for i, (name, form_id, key) in enumerate(item_list):\n",
        "            kept_id = kept_map.get(key, \"N/A\")\n",
        "            name_str = str(name)[:55] + \"...\" if len(str(name)) > 55 else str(name)\n",
        "            print(f\"{name_str:<60} | {str(form_id):<20} | {str(kept_id):<20}\")\n",
        "\n",
        "        print(\"=\" * 110)\n",
        "\n",
        "    ref_choices = df_ref_unique['clean_key'].tolist()\n",
        "    ref_map = df_ref_unique.set_index('clean_key')[['FORM_ID_KONTRAK_PAYUNG', 'ItemPekerjaan']].to_dict('index')\n",
        "\n",
        "    # --- 3. EXECUTION LOOP ---\n",
        "    col_target = 'FORM_ID (KontrakPayung)'\n",
        "    col_key = 'ItemPekerjaan'\n",
        "\n",
        "    # === UPDATE ANTI-SKIP (LOGIKA BARU) ===\n",
        "    def needs_processing(row):\n",
        "        val = str(row[col_target]).lower().strip()\n",
        "        # TARGET: Kosong atau 'skip'/'skp'.\n",
        "        # Selain itu (misal text random) tidak diproses match, dan nanti dihapus.\n",
        "        target_keywords = ['skip', 'skp', 'nan', 'null', '', 'none']\n",
        "        is_target = val in target_keywords or pd.isna(row[col_target])\n",
        "\n",
        "        conf = str(row.get('CONFIDENCE_LEVEL', '')).upper()\n",
        "        is_locked = conf in ['PERFECT', 'HIGH']\n",
        "        return is_target and not is_locked\n",
        "\n",
        "    mask = df_target.apply(needs_processing, axis=1)\n",
        "    indices = df_target[mask].index\n",
        "    total = len(indices)\n",
        "\n",
        "    print(f\"\\nüöÄ Memulai INTELLIGENT FALLBACK untuk {total} baris (termasuk 'skp')...\")\n",
        "\n",
        "    stats = {'PERFECT':0, 'HIGH':0, 'GOOD':0, 'FAIR':0, 'FORCED':0, 'LAST_RESORT':0, 'FAILED':0}\n",
        "    memo = {}\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        original = str(df_target.at[idx, col_key])\n",
        "        query = preprocess_text(original)\n",
        "\n",
        "        if not query or len(query) < 2:\n",
        "            df_target.at[idx, 'CONFIDENCE_LEVEL'] = 'FAILED'\n",
        "            stats['FAILED'] += 1\n",
        "            continue\n",
        "\n",
        "        if query in memo:\n",
        "            best_match, score = memo[query]\n",
        "        else:\n",
        "            result = process.extractOne(query, ref_choices, scorer=fuzz.token_set_ratio)\n",
        "            if result:\n",
        "                best_match, score = result\n",
        "                memo[query] = (best_match, score)\n",
        "            else:\n",
        "                best_match, score = None, 0\n",
        "\n",
        "        if not best_match:\n",
        "            stats['FAILED'] += 1\n",
        "            continue\n",
        "\n",
        "        ref_data = ref_map.get(best_match)\n",
        "        ref_id = ref_data['FORM_ID_KONTRAK_PAYUNG']\n",
        "        ref_name = ref_data['ItemPekerjaan']\n",
        "\n",
        "        common_words = get_common_words_count(query, str(best_match))\n",
        "\n",
        "        level = \"LAST_RESORT\"\n",
        "        reason = f\"Score {score} (Desperate)\"\n",
        "\n",
        "        if score >= 90:\n",
        "            level = \"PERFECT\"; reason = \"Score 90+\"\n",
        "        elif score >= 80:\n",
        "            if common_words >= 1: level = \"HIGH\"; reason = \"Score 80+ & 1 KW\"\n",
        "            else: level = \"GOOD\"; reason = \"Score 80+ No KW\"\n",
        "        elif score >= 70:\n",
        "            if common_words >= 2: level = \"GOOD\"; reason = \"Score 70+ & 2 KW\"\n",
        "            elif common_words >= 1: level = \"FAIR\"; reason = \"Score 70+ & 1 KW\"\n",
        "            else: level = \"FORCED\"; reason = \"Score 70+ No KW\"\n",
        "        elif score >= 60:\n",
        "            if common_words >= 2: level = \"FAIR\"; reason = \"Score 60+ & 2 KW\"\n",
        "            else: level = \"FORCED\"; reason = \"Score 60+ Weak KW\"\n",
        "        elif score >= 50:\n",
        "            level = \"FORCED\"; reason = \"Score 50+\"\n",
        "\n",
        "        df_target.at[idx, col_target] = ref_id\n",
        "        df_target.at[idx, 'CONFIDENCE_LEVEL'] = level\n",
        "        df_target.at[idx, 'MATCH_SCORE'] = score\n",
        "        df_target.at[idx, 'MATCH_REASON'] = reason\n",
        "        df_target.at[idx, 'SARAN_NAMA_ITEM'] = ref_name\n",
        "\n",
        "        stats[level] += 1\n",
        "\n",
        "        if (i+1) % 500 == 0:\n",
        "            print(f\"   ... {i+1}/{total} | P:{stats['PERFECT']} H:{stats['HIGH']} F:{stats['FORCED']} L:{stats['LAST_RESORT']}\")\n",
        "\n",
        "    print(\"\\n‚úÖ SELESAI! Breakdown Hasil:\")\n",
        "    for k, v in stats.items():\n",
        "        print(f\"   - {k}: {v} baris\")\n",
        "\n",
        "    # --- 4. FINAL CLEANUP (HAPUS NON-NUMBER) ---\n",
        "    print(\"\\nüßπ Final Cleanup: Menghapus baris dengan FORM_ID bukan angka...\")\n",
        "    before_len = len(df_target)\n",
        "\n",
        "    # Paksa ke numeric, text jadi NaN\n",
        "    df_target[col_target] = pd.to_numeric(df_target[col_target], errors='coerce')\n",
        "\n",
        "    # Drop NaN\n",
        "    df_clean = df_target.dropna(subset=[col_target])\n",
        "    after_len = len(df_clean)\n",
        "\n",
        "    print(f\"   - Baris dihapus: {before_len - after_len}\")\n",
        "    print(f\"   - Total Akhir: {after_len}\")\n",
        "\n",
        "    df_target = df_clean\n",
        "\n",
        "    print(f\"\\nüíæ Menyimpan ke '{output_filename}'...\")\n",
        "    df_target.to_excel(output_filename, index=False)\n",
        "    if IN_COLAB:\n",
        "        files.download(output_filename)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    fill_missing_form_id_v7_final()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II2bQRJTddwJ",
        "outputId": "4c7e3391-4ee7-4fab-cfb7-b71e763a74b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Menginstall python-Levenshtein...\n",
            "üì¶ Menginstall scikit-learn...\n",
            "üìÇ Membaca file '2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx'...\n",
            "‚ùå File tidak ditemukan. Harap upload file terlebih dahulu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Otomatisasi Pengisian FORM_ID (V5.2: SAPU JAGAT + LOG + ANTI-SKIP)\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "try:\n",
        "    from thefuzz import process, fuzz\n",
        "except ImportError:\n",
        "    print(\"Module 'thefuzz' not found. Installing...\")\n",
        "    import subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"thefuzz[speedup]\"])\n",
        "    from thefuzz import process, fuzz\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isna(text): return \"\"\n",
        "    text = str(text).lower().strip()\n",
        "    text = re.sub(r'[^\\w\\s\\-\\\"\\./]', ' ', text)\n",
        "    if '>' in text:\n",
        "        parts = text.split('>')\n",
        "        last = parts[-1].strip()\n",
        "        if len(last) < 3 and len(parts) > 1:\n",
        "            text = parts[-2].strip() + \" \" + last\n",
        "        else:\n",
        "            text = last\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def fill_missing_form_id_v5_final():\n",
        "    input_file = '2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx'\n",
        "    output_filename = 'Hasil_Mapping_FINAL_V5.xlsx'\n",
        "\n",
        "    print(f\"\\nüì• Membaca input dari: {input_file}\")\n",
        "    if not os.path.exists(input_file):\n",
        "        if IN_COLAB:\n",
        "            print(\"File tidak ditemukan. Upload manual.\")\n",
        "            uploaded = files.upload()\n",
        "            if uploaded: input_file = list(uploaded.keys())[0]\n",
        "            else: return\n",
        "        else:\n",
        "            print(f\"File {input_file} tidak ditemukan.\")\n",
        "            return\n",
        "\n",
        "    xls = pd.ExcelFile(input_file, engine='openpyxl')\n",
        "    try: df_target = pd.read_excel(xls, sheet_name='ItemTambahanKontarPayung')\n",
        "    except: df_target = pd.read_excel(xls, sheet_name=0)\n",
        "\n",
        "    try: df_ref = pd.read_excel(xls, sheet_name='ItemKontrakPayung')\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è Sheet referensi tidak ditemukan. Upload file ASLI.\")\n",
        "        if IN_COLAB:\n",
        "            uploaded = files.upload()\n",
        "            fn = list(uploaded.keys())[0]\n",
        "            df_ref = pd.read_excel(fn, sheet_name='ItemKontrakPayung')\n",
        "        else: return\n",
        "\n",
        "    print(f\"‚úÖ Data dimuat. Target: {len(df_target)}, Ref: {len(df_ref)}\")\n",
        "\n",
        "    # --- LOG DUPLIKAT ---\n",
        "    print(\"\\nüßπ Membersihkan & Cek Duplikasi Referensi...\")\n",
        "    df_ref['clean_key'] = df_ref['ItemPekerjaan'].apply(preprocess_text)\n",
        "\n",
        "    dup_mask = df_ref.duplicated(subset=['clean_key'], keep='first')\n",
        "    removed_items = df_ref[dup_mask].copy()\n",
        "    df_ref_unique = df_ref.drop_duplicates(subset=['clean_key'], keep='first')\n",
        "\n",
        "    removed_count = len(df_ref) - len(df_ref_unique)\n",
        "    print(f\"   - Duplikat Dihapus: {removed_count} baris\")\n",
        "\n",
        "    if removed_count > 0:\n",
        "        print(\"\\nüìã DAFTAR LENGKAP ITEM YANG DIHAPUS (DUPLIKAT):\")\n",
        "        print(\"=\" * 110)\n",
        "        print(f\"{'NAMA ITEM':<60} | {'ID DIBUANG':<20} | {'ID DIPAKAI':<20}\")\n",
        "        print(\"=\" * 110)\n",
        "        kept_map = df_ref_unique.set_index('clean_key')['FORM_ID_KONTRAK_PAYUNG'].to_dict()\n",
        "        item_list = removed_items[['ItemPekerjaan', 'FORM_ID_KONTRAK_PAYUNG', 'clean_key']].values.tolist()\n",
        "        for i, (name, form_id, key) in enumerate(item_list):\n",
        "            kept_id = kept_map.get(key, \"N/A\")\n",
        "            name_str = str(name)[:55] + \"...\" if len(str(name)) > 55 else str(name)\n",
        "            print(f\"{name_str:<60} | {str(form_id):<20} | {str(kept_id):<20}\")\n",
        "        print(\"=\" * 110)\n",
        "\n",
        "    ref_choices = df_ref_unique['clean_key'].tolist()\n",
        "    ref_map = df_ref_unique.set_index('clean_key')['FORM_ID_KONTRAK_PAYUNG'].to_dict()\n",
        "\n",
        "    # --- MATCHING ---\n",
        "    col_target_fill = 'FORM_ID (KontrakPayung)'\n",
        "    col_key = 'ItemPekerjaan'\n",
        "\n",
        "    # === UPDATE ANTI-SKIP ===\n",
        "    def is_empty_or_skip(val):\n",
        "        s = str(val).lower().strip()\n",
        "        invalid_keywords = ['skip', 'skp', 'nan', 'null', 'nil', '-', '', '#n/a']\n",
        "        return s in invalid_keywords or pd.isna(val)\n",
        "\n",
        "    mask_to_fill = df_target[col_target_fill].apply(is_empty_or_skip)\n",
        "    indices = df_target[mask_to_fill].index\n",
        "\n",
        "    total_items = len(indices)\n",
        "    print(f\"üéØ Target sisa yang harus diisi: {total_items} baris.\")\n",
        "\n",
        "    matches_found = 0\n",
        "    memo = {}\n",
        "\n",
        "    print(\"‚öôÔ∏è Memulai FUZZY MATCHING...\")\n",
        "    for i, idx in enumerate(indices):\n",
        "        original_text = df_target.at[idx, col_key]\n",
        "        query_text = preprocess_text(original_text)\n",
        "\n",
        "        if not query_text or len(query_text) < 2:\n",
        "            df_target.at[idx, col_target_fill] = \"DATA_TIDAK_VALID\"\n",
        "            continue\n",
        "\n",
        "        if query_text in memo:\n",
        "            best_match, score = memo[query_text]\n",
        "        else:\n",
        "            result = process.extractOne(query_text, ref_choices, scorer=fuzz.token_set_ratio)\n",
        "            if result:\n",
        "                best_match, score = result\n",
        "                memo[query_text] = (best_match, score)\n",
        "            else:\n",
        "                best_match, score = None, 0\n",
        "\n",
        "        final_val = None\n",
        "        if score >= 80: final_val = ref_map.get(best_match)\n",
        "        elif score >= 60: final_val = ref_map.get(best_match)\n",
        "\n",
        "        if final_val:\n",
        "            df_target.at[idx, col_target_fill] = final_val\n",
        "            matches_found += 1\n",
        "        else:\n",
        "            df_target.at[idx, col_target_fill] = \"TIDAK_DITEMUKAN_DI_REF\"\n",
        "\n",
        "        if (i + 1) % 500 == 0:\n",
        "            print(f\"   ...Sisa diproses {i + 1}/{total_items} | Baru dpt: {matches_found}\")\n",
        "\n",
        "    print(f\"\\n‚úÖ SELESAI TOTAL! Berhasil menambah: {matches_found} data baru.\")\n",
        "    sisa_skip = df_target[col_target_fill].apply(lambda x: str(x).lower().strip() == 'skp').sum()\n",
        "    print(f\"   Sisa 'skp': {sisa_skip}\")\n",
        "\n",
        "    print(f\"üíæ Menyimpan ke '{output_filename}'...\")\n",
        "    df_target.to_excel(output_filename, index=False)\n",
        "    if IN_COLAB: files.download(output_filename)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    fill_missing_form_id_v5_final()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "7ZtJWpr4Wdzv",
        "outputId": "f4e50536-dbb4-4c2c-a66d-ec4ab732516d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Module 'thefuzz' not found. Installing...\n",
            "\n",
            "üì• Membaca input dari: 2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx\n",
            "File tidak ditemukan. Upload manual.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5bafd365-3e1a-4ba4-966a-da8b626482d8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5bafd365-3e1a-4ba4-966a-da8b626482d8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1749924333.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mfill_missing_form_id_v5_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1749924333.py\u001b[0m in \u001b[0;36mfill_missing_form_id_v5_final\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mIN_COLAB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File tidak ditemukan. Upload manual.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    162\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    163\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 1: INSTALASI & SETUP (AUTO-RUN)\n",
        "# ==========================================\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Cek & Install Library Otomatis\n",
        "try:\n",
        "    import thefuzz\n",
        "    import Levenshtein\n",
        "    print(\"‚úÖ Library 'thefuzz' & 'python-Levenshtein' sudah terinstall.\")\n",
        "except ImportError:\n",
        "    print(\"‚öôÔ∏è Sedang menginstall library 'thefuzz' & 'python-Levenshtein'...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"thefuzz\", \"python-Levenshtein\"])\n",
        "    print(\"‚úÖ Instalasi selesai.\")\n",
        "    import thefuzz\n",
        "    import Levenshtein\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from thefuzz import fuzz, process\n",
        "import re\n",
        "import time\n",
        "from google.colab import files # Khusus Google Colab\n",
        "\n",
        "# ==========================================\n",
        "# BAGIAN 2: KONFIGURASI FILE\n",
        "# ==========================================\n",
        "# Nama file saja (tanpa C:\\Users\\...) karena di Colab file ada di root folder\n",
        "FILENAME = '2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx'\n",
        "OUTPUT_FILE = 'Hasil_Mapping_V8_Smart.xlsx'\n",
        "\n",
        "# Cek File - Jika tidak ada, minta User Upload\n",
        "if not os.path.exists(FILENAME):\n",
        "    print(f\"\\n‚ö†Ô∏è File '{FILENAME}' belum ditemukan di Colab.\")\n",
        "    print(\"üìÇ Silakan pilih file Excel Anda sekarang (Upload window akan muncul)...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Ambil nama file yang baru diupload (jaga-jaga user rename)\n",
        "    if uploaded:\n",
        "        FILENAME = list(uploaded.keys())[0]\n",
        "        print(f\"‚úÖ File ditemukan: {FILENAME}\")\n",
        "    else:\n",
        "        print(\"‚ùå Upload dibatalkan. Script berhenti.\")\n",
        "        sys.exit()\n",
        "else:\n",
        "    print(f\"‚úÖ File ditemukan: {FILENAME}\")\n",
        "\n",
        "# ==========================================\n",
        "# BAGIAN 3: FUNGSI UTILITIES\n",
        "# ==========================================\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isna(text): return \"\"\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s\\->]', ' ', text) # Keep '>' for hierarchy\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def get_leaf_node(text):\n",
        "    if '>' in text:\n",
        "        return text.split('>')[-1].strip()\n",
        "    return text\n",
        "\n",
        "def is_valid_target(val):\n",
        "    # True jika PERLU DIISI (NaN atau Text seperti 'skip')\n",
        "    # False jika SUDAH TERISI (Angka valid)\n",
        "    if pd.isna(val):\n",
        "        return True\n",
        "    try:\n",
        "        float(val)\n",
        "        return False\n",
        "    except ValueError:\n",
        "        return True\n",
        "\n",
        "def extract_keywords(text_series):\n",
        "    all_tokens = set()\n",
        "    for text in text_series:\n",
        "        tokens = str(text).split()\n",
        "        for t in tokens:\n",
        "            if len(t) > 2:\n",
        "                all_tokens.add(t)\n",
        "    return all_tokens\n",
        "\n",
        "# ==========================================\n",
        "# BAGIAN 4: ENGINE UTAMA (V8.1)\n",
        "# ==========================================\n",
        "\n",
        "def run_smart_mapping():\n",
        "    print(f\"\\nüöÄ MEMULAI PROSES V8.1 (SMART HIERARCHY)...\")\n",
        "\n",
        "    # --- LOAD DATA ---\n",
        "    print(\"üìÇ Membaca Excel...\")\n",
        "    try:\n",
        "        xl = pd.ExcelFile(FILENAME)\n",
        "        sheet_target = 'ItemTambahanKontarPayung' if 'ItemTambahanKontarPayung' in xl.sheet_names else xl.sheet_names[0]\n",
        "\n",
        "        sheet_ref = None\n",
        "        for name in xl.sheet_names:\n",
        "            if 'ItemKontrakPayung' in name and name != sheet_target:\n",
        "                sheet_ref = name\n",
        "                break\n",
        "        if not sheet_ref and len(xl.sheet_names) > 1:\n",
        "            sheet_ref = xl.sheet_names[1]\n",
        "\n",
        "        print(f\"   Target: {sheet_target} | Referensi: {sheet_ref}\")\n",
        "\n",
        "        df_target = xl.parse(sheet_target)\n",
        "        df_ref = xl.parse(sheet_ref)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error read file: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- PREPROCESSING REFERENSI ---\n",
        "    print(\"‚öôÔ∏è Indexing Referensi...\")\n",
        "    col_ref_item = 'ItemPekerjaan'\n",
        "    col_ref_id = 'FORM_ID_KONTRAK_PAYUNG'\n",
        "    col_ref_satuan = 'Satuan'\n",
        "\n",
        "    df_ref['clean_item'] = df_ref[col_ref_item].apply(preprocess_text)\n",
        "    if col_ref_satuan in df_ref.columns:\n",
        "        df_ref['clean_satuan'] = df_ref[col_ref_satuan].apply(preprocess_text)\n",
        "        subset_cols = ['clean_item', 'clean_satuan']\n",
        "    else:\n",
        "        subset_cols = ['clean_item']\n",
        "\n",
        "    df_ref_clean = df_ref.drop_duplicates(subset=subset_cols, keep='first')\n",
        "    df_ref_clean = df_ref_clean[df_ref_clean['clean_item'] != \"\"]\n",
        "\n",
        "    ref_dict = dict(zip(df_ref_clean['clean_item'], df_ref_clean[col_ref_id]))\n",
        "    ref_keys = list(ref_dict.keys())\n",
        "    valid_keywords = extract_keywords(df_ref_clean['clean_item'])\n",
        "\n",
        "    print(f\"   Referensi Unik: {len(df_ref_clean)} Items\")\n",
        "\n",
        "    # --- PREPROCESSING TARGET ---\n",
        "    col_target_item = 'ItemPekerjaan'\n",
        "    col_target_id = 'FORM_ID (KontrakPayung)'\n",
        "\n",
        "    target_mask = df_target[col_target_id].apply(is_valid_target)\n",
        "    indices = df_target[target_mask].index\n",
        "    print(f\"   Target Kosong/Skip: {len(indices)} Baris\")\n",
        "\n",
        "    # Siapkan Kolom\n",
        "    for col in ['STATUS_MATCH', 'MATCH_SCORE', 'MATCH_SOURCE', 'SARAN_MATCH']:\n",
        "        if col not in df_target.columns:\n",
        "            df_target[col] = \"\"\n",
        "\n",
        "    # --- MATCHING LOOP ---\n",
        "    print(\"\\n‚ö° SEARCHING MATCHES...\")\n",
        "    start_time = time.time()\n",
        "    filled, reviewed = 0, 0\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        if i % 50 == 0: print(f\"   Processing {i}/{len(indices)}...\", end='\\r')\n",
        "\n",
        "        orig_txt = str(df_target.at[idx, col_target_item])\n",
        "        clean_full = preprocess_text(orig_txt)\n",
        "        if not clean_full: continue\n",
        "\n",
        "        # 1. Exact Match\n",
        "        if clean_full in ref_dict:\n",
        "            df_target.at[idx, col_target_id] = ref_dict[clean_full]\n",
        "            df_target.at[idx, 'STATUS_MATCH'] = 'PERFECT (Exact)'\n",
        "            df_target.at[idx, 'MATCH_SCORE'] = 100\n",
        "            filled += 1\n",
        "            continue\n",
        "\n",
        "        # 2. Fuzzy Full\n",
        "        best = process.extractOne(clean_full, ref_keys, scorer=fuzz.token_set_ratio)\n",
        "        cand, score = best[0], best[1]\n",
        "        src = \"Full String\"\n",
        "\n",
        "        # 3. Smart Hierarchy (Leaf Node)\n",
        "        if score < 85 and '>' in orig_txt:\n",
        "            leaf_clean = preprocess_text(get_leaf_node(orig_txt))\n",
        "            if leaf_clean in ref_dict:\n",
        "                cand, score = leaf_clean, 95\n",
        "                src = \"Leaf Node (Exact)\"\n",
        "            else:\n",
        "                best_leaf = process.extractOne(leaf_clean, ref_keys, scorer=fuzz.token_set_ratio)\n",
        "                if best_leaf[1] > score + 5:\n",
        "                    cand, score = best_leaf[0], best_leaf[1]\n",
        "                    src = \"Leaf Node (Fuzzy)\"\n",
        "\n",
        "        # 4. Keyword Check\n",
        "        cand_toks = set(cand.split())\n",
        "        tgt_toks = set(clean_full.split())\n",
        "        if \"Leaf\" in src:\n",
        "            tgt_toks = set(preprocess_text(get_leaf_node(orig_txt)).split())\n",
        "        common = len(cand_toks.intersection(tgt_toks).intersection(valid_keywords))\n",
        "\n",
        "        # 5. Decision\n",
        "        matched_id = ref_dict[cand]\n",
        "        status, action = \"\", \"SKIP\"\n",
        "\n",
        "        if score >= 90:\n",
        "            status, action = \"PERFECT\", \"AUTO\"\n",
        "        elif score >= 80 and common >= 1:\n",
        "            status, action = \"HIGH\", \"AUTO\"\n",
        "        elif score >= 60 and common >= 1:\n",
        "            status, action = \"GOOD/FAIR\", \"REVIEW\"\n",
        "        elif score >= 50:\n",
        "            status, action = \"FORCED\", \"REVIEW\"\n",
        "        else:\n",
        "            status, action = \"LAST_RESORT\", \"REVIEW\"\n",
        "\n",
        "        df_target.at[idx, 'MATCH_SCORE'] = score\n",
        "        df_target.at[idx, 'MATCH_SOURCE'] = src\n",
        "\n",
        "        if action == \"AUTO\":\n",
        "            df_target.at[idx, col_target_id] = matched_id\n",
        "            df_target.at[idx, 'STATUS_MATCH'] = status\n",
        "            filled += 1\n",
        "        elif action == \"REVIEW\":\n",
        "            df_target.at[idx, col_target_id] = matched_id\n",
        "            df_target.at[idx, 'STATUS_MATCH'] = status\n",
        "            df_target.at[idx, 'SARAN_MATCH'] = f\"{cand} (ID: {matched_id})\"\n",
        "            reviewed += 1\n",
        "\n",
        "    print(f\"\\n‚úÖ SELESAI! Waktu: {time.time()-start_time:.1f}s\")\n",
        "    print(f\"   - Auto Filled: {filled}\")\n",
        "    print(f\"   - Butuh Review: {reviewed}\")\n",
        "\n",
        "    df_target.to_excel(OUTPUT_FILE, index=False)\n",
        "    print(f\"üíæ File hasil tersimpan: {OUTPUT_FILE}\")\n",
        "    print(\"   (Refresh panel kiri untuk melihat file)\")\n",
        "\n",
        "# Run\n",
        "run_smart_mapping()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "MhBtJsCkjpJ2",
        "outputId": "0fddc6ac-61e0-48c4-d666-92caa22a79f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Library 'thefuzz' & 'python-Levenshtein' sudah terinstall.\n",
            "\n",
            "‚ö†Ô∏è File '2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx' belum ditemukan di Colab.\n",
            "üìÇ Silakan pilih file Excel Anda sekarang (Upload window akan muncul)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9a3c15df-7134-4078-ab0d-c1e784d199d5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9a3c15df-7134-4078-ab0d-c1e784d199d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx to 2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx\n",
            "‚úÖ File ditemukan: 2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx\n",
            "\n",
            "üöÄ MEMULAI PROSES V8.1 (SMART HIERARCHY)...\n",
            "üìÇ Membaca Excel...\n",
            "   Target: ItemTambahanKontarPayung | Referensi: ItemKontrakPayung\n",
            "‚öôÔ∏è Indexing Referensi...\n",
            "   Referensi Unik: 3247 Items\n",
            "   Target Kosong/Skip: 20112 Baris\n",
            "\n",
            "‚ö° SEARCHING MATCHES...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:thefuzz.process:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:thefuzz.process:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-605476193.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;31m# Run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m \u001b[0mrun_smart_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-605476193.py\u001b[0m in \u001b[0;36mrun_smart_mapping\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# 2. Fuzzy Full\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_set_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mcand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Full String\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/thefuzz/process.py\u001b[0m in \u001b[0;36mextractOne\u001b[0;34m(query, choices, processor, scorer, score_cutoff)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_preprocess_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     res = rprocess.extractOne(\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/rapidfuzz/process_cpp_impl.pyx\u001b[0m in \u001b[0;36mrapidfuzz.process_cpp_impl.extractOne\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/rapidfuzz/process_cpp_impl.pyx\u001b[0m in \u001b[0;36mrapidfuzz.process_cpp_impl.extractOne_list\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/rapidfuzz/process_cpp_impl.pyx\u001b[0m in \u001b[0;36mrapidfuzz.process_cpp_impl.extractOne_list_f64\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/thefuzz/utils.py\u001b[0m in \u001b[0;36mfull_process\u001b[0;34m(s, force_ascii)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mfull_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \"\"\"\n\u001b[1;32m     12\u001b[0m     \u001b[0mProcess\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 1. SETUP\n",
        "# ==========================================\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "try:\n",
        "    import rapidfuzz\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"rapidfuzz\"])\n",
        "    import rapidfuzz\n",
        "\n",
        "import pandas as pd\n",
        "from rapidfuzz import process, fuzz\n",
        "from google.colab import files\n",
        "import re\n",
        "\n",
        "# ==========================================\n",
        "# 2. CONFIG & UPLOAD\n",
        "# ==========================================\n",
        "FILENAME = '2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx'\n",
        "OUTPUT_FILE = 'Hasil_Mapping_V11_RootStripper.xlsx'\n",
        "\n",
        "if not os.path.exists(FILENAME):\n",
        "    print(f\"üìÇ Upload '{FILENAME}'...\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded: FILENAME = list(uploaded.keys())[0]\n",
        "\n",
        "# ==========================================\n",
        "# 3. LOGIKA BARU: ROOT STRIPPING\n",
        "# ==========================================\n",
        "def preprocess(text):\n",
        "    if pd.isna(text): return \"\"\n",
        "    return str(text).lower().strip()\n",
        "\n",
        "def get_core_content(text):\n",
        "    \"\"\"\n",
        "    Logika V11: Membuang Root/Kategori Umum di depan,\n",
        "    tapi mempertahankan Tengah + Belakang.\n",
        "    \"\"\"\n",
        "    text = str(text)\n",
        "    if '>' not in text:\n",
        "        return text\n",
        "\n",
        "    parts = [p.strip() for p in text.split('>')]\n",
        "\n",
        "    # Daftar Kategori Umum yang WAJIB DIBUANG jika ada di Level 1 atau 2\n",
        "    # Anda bisa menambahkan kata lain di sini sesuai data Anda\n",
        "    garbage_roots = [\n",
        "        'MATERIAL', 'ADDITIONAL WORKS', 'JASA', 'PEKERJAAN',\n",
        "        'FITTING & FLANGES STEEL', 'PIPE CARBON STEEL', 'VALVE',\n",
        "        'INSTRUMENT', 'ELECTRICAL', 'CIVIL', 'MECHANICAL'\n",
        "    ]\n",
        "\n",
        "    # Cek Level 1 (Index 0)\n",
        "    start_index = 0\n",
        "    if len(parts) > 1 and parts[0].upper() in garbage_roots:\n",
        "        start_index = 1\n",
        "\n",
        "        # Cek Level 2 (Index 1) - Jika Level 1 sudah dibuang, cek selanjutnya\n",
        "        if len(parts) > 2 and parts[1].upper() in garbage_roots:\n",
        "            start_index = 2\n",
        "\n",
        "    # Ambil mulai dari index yang valid sampai akhir, gabung ulang\n",
        "    core_parts = parts[start_index:]\n",
        "    return \" > \".join(core_parts)\n",
        "\n",
        "memo_cache = {}\n",
        "\n",
        "# ==========================================\n",
        "# 4. ENGINE V11\n",
        "# ==========================================\n",
        "def run_root_stripper():\n",
        "    print(f\"\\nüå≥ STARTING V11 ROOT STRIPPER...\")\n",
        "\n",
        "    xl = pd.ExcelFile(FILENAME)\n",
        "    df_tgt = xl.parse(xl.sheet_names[0])\n",
        "    df_ref = xl.parse(xl.sheet_names[1])\n",
        "\n",
        "    # Preprocess Referensi\n",
        "    df_ref['clean'] = df_ref['ItemPekerjaan'].apply(preprocess)\n",
        "\n",
        "    # KITA TERAPKAN LOGIKA SAMA KE REFERENSI\n",
        "    # Agar Referensi juga \"bersih\" dari kategori umum (jika ada)\n",
        "    df_ref['clean_core'] = df_ref['ItemPekerjaan'].apply(lambda x: preprocess(get_core_content(x)))\n",
        "\n",
        "    df_ref = df_ref.drop_duplicates(subset=['clean_core']) # Deduplikasi berdasarkan Core\n",
        "\n",
        "    ref_cores = df_ref['clean_core'].tolist()\n",
        "    ref_ids = df_ref['FORM_ID_KONTRAK_PAYUNG'].tolist()\n",
        "    ref_map = dict(zip(ref_cores, ref_ids)) # Map: Core Text -> ID\n",
        "\n",
        "    # Filter Target\n",
        "    col_tgt_id = 'FORM_ID (KontrakPayung)'\n",
        "    tgt_indices = df_tgt[df_tgt[col_tgt_id].apply(lambda x: pd.isna(x) or not str(x).replace('.','').isdigit())].index\n",
        "\n",
        "    print(f\"   Target: {len(tgt_indices)} baris.\")\n",
        "    print(\"   Processing...\")\n",
        "\n",
        "    for idx in tgt_indices:\n",
        "        raw_txt = str(df_tgt.at[idx, 'ItemPekerjaan'])\n",
        "\n",
        "        # --- IMPLEMENTASI LOGIKA BARU ---\n",
        "        # Ambil Core Content (Tengah + Belakang)\n",
        "        core_txt = get_core_content(raw_txt)\n",
        "        clean_core = preprocess(core_txt)\n",
        "\n",
        "        if clean_core in memo_cache:\n",
        "            res = memo_cache[clean_core]\n",
        "        else:\n",
        "            # 1. Exact Core Match\n",
        "            if clean_core in ref_map:\n",
        "                res = (ref_map[clean_core], 100, \"PERFECT\", \"Core Exact\")\n",
        "            else:\n",
        "                # 2. Fuzzy Core Match\n",
        "                match = process.extractOne(clean_core, ref_cores, scorer=fuzz.token_set_ratio)\n",
        "                cand, score = match[0], match[1]\n",
        "\n",
        "                status = \"AUTO\" if score >= 85 else \"REVIEW\"\n",
        "                found_id = ref_map.get(cand)\n",
        "                res = (found_id, score, status, f\"Matched: {cand}\")\n",
        "\n",
        "            memo_cache[clean_core] = res\n",
        "\n",
        "        # Assign\n",
        "        mid, sc, st, note = res\n",
        "        df_tgt.at[idx, col_tgt_id] = mid\n",
        "        df_tgt.at[idx, 'STATUS_MATCH'] = st\n",
        "        df_tgt.at[idx, 'MATCH_SCORE'] = sc\n",
        "        if st == \"REVIEW\":\n",
        "            df_tgt.at[idx, 'SARAN_MATCH'] = f\"{note} (ID: {mid})\"\n",
        "\n",
        "    print(\"‚úÖ SELESAI!\")\n",
        "    df_tgt.to_excel(OUTPUT_FILE, index=False)\n",
        "    files.download(OUTPUT_FILE)\n",
        "\n",
        "run_root_stripper()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "zWZa1IhTv1B_",
        "outputId": "5e58eea2-64a9-4a8b-bb3b-a2981ae5ae5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üå≥ STARTING V11 ROOT STRIPPER...\n",
            "   Target: 20112 baris.\n",
            "   Processing...\n",
            "‚úÖ SELESAI!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_87cf3bed-aa53-4369-9eb5-ba877f16fd3d\", \"Hasil_Mapping_V11_RootStripper.xlsx\", 3240500)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 1. SETUP\n",
        "# ==========================================\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "try:\n",
        "    import rapidfuzz\n",
        "    from tqdm import tqdm # Library untuk progress bar\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"rapidfuzz\", \"tqdm\"])\n",
        "    import rapidfuzz\n",
        "    from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "from rapidfuzz import process, fuzz\n",
        "from google.colab import files\n",
        "\n",
        "# ==========================================\n",
        "# 2. CONFIG\n",
        "# ==========================================\n",
        "FILENAME = '2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx'\n",
        "OUTPUT_FILE = 'Hasil_Mapping_V14_Monitoring.xlsx'\n",
        "LOG_FILE = 'Log_Duplikat_Dihapus.csv'\n",
        "\n",
        "if not os.path.exists(FILENAME):\n",
        "    print(f\"üìÇ Upload '{FILENAME}'...\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded: FILENAME = list(uploaded.keys())[0]\n",
        "\n",
        "# ==========================================\n",
        "# 3. LOGIKA PARSING (V13/V14)\n",
        "# ==========================================\n",
        "def preprocess(text):\n",
        "    if pd.isna(text): return \"\"\n",
        "    return str(text).lower().strip()\n",
        "\n",
        "def get_content_parser(text):\n",
        "    text = str(text).strip()\n",
        "\n",
        "    # RULE 1: PRIORITAS TERTINGGI - SPLIT BY \" - \"\n",
        "    if ' - ' in text:\n",
        "        parts = text.split(' - ')\n",
        "        last_part = parts[-1].strip()\n",
        "        if len(last_part) < 3 and len(parts) >= 2:\n",
        "            return parts[-2].strip() + \" - \" + last_part\n",
        "        return last_part\n",
        "\n",
        "    # RULE 2: ROOT STRIPPING\n",
        "    if '>' in text:\n",
        "        parts = [p.strip() for p in text.split('>')]\n",
        "        garbage_roots = [\n",
        "            'MATERIAL', 'ADDITIONAL WORKS', 'JASA', 'PEKERJAAN',\n",
        "            'FITTING & FLANGES STEEL', 'PIPE CARBON STEEL', 'VALVE',\n",
        "            'INSTRUMENT', 'ELECTRICAL', 'CIVIL', 'MECHANICAL'\n",
        "        ]\n",
        "        start_idx = 0\n",
        "        if len(parts) > 1 and parts[0].upper() in garbage_roots:\n",
        "            start_idx = 1\n",
        "            if len(parts) > 2 and parts[1].upper() in garbage_roots:\n",
        "                start_idx = 2\n",
        "        return \" > \".join(parts[start_idx:])\n",
        "\n",
        "    # RULE 3: BERSIH\n",
        "    return text\n",
        "\n",
        "# ==========================================\n",
        "# 4. ENGINE V14 (MONITORING)\n",
        "# ==========================================\n",
        "def run_monitoring_engine():\n",
        "    print(f\"\\nüìä STARTING V14 FULL MONITORING SYSTEM...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # --- LOAD DATA ---\n",
        "    print(\"üìÇ Membaca file Excel...\")\n",
        "    xl = pd.ExcelFile(FILENAME)\n",
        "    df_tgt = xl.parse(xl.sheet_names[0])\n",
        "    df_ref = xl.parse(xl.sheet_names[1])\n",
        "    print(f\"   - Target Rows: {len(df_tgt)}\")\n",
        "    print(f\"   - Ref Rows: {len(df_ref)}\")\n",
        "\n",
        "    # --- REFERENCE AUDIT ---\n",
        "    print(\"\\nüîç Mengaudit Data Referensi...\")\n",
        "    df_ref['Parsed_Content'] = df_ref['ItemPekerjaan'].apply(get_content_parser)\n",
        "    df_ref['Clean_Key'] = df_ref['Parsed_Content'].apply(preprocess)\n",
        "\n",
        "    # Cek Duplikat\n",
        "    # Kita simpan duplikat untuk log\n",
        "    duplicates = df_ref[df_ref.duplicated(subset=['Clean_Key'], keep='first')].copy()\n",
        "\n",
        "    if not duplicates.empty:\n",
        "        print(f\"‚ö†Ô∏è  Ditemukan {len(duplicates)} duplikat dalam Referensi.\")\n",
        "        print(f\"üìù Menyimpan log duplikat ke '{LOG_FILE}'...\")\n",
        "        # Simpan detail duplikat\n",
        "        duplicates[['FORM_ID_KONTRAK_PAYUNG', 'ItemPekerjaan', 'Parsed_Content']].to_csv(LOG_FILE, index=False)\n",
        "    else:\n",
        "        print(\"‚úÖ Data Referensi Unik & Bersih.\")\n",
        "\n",
        "    # Hapus duplikat dari dataset kerja\n",
        "    df_ref_clean = df_ref.drop_duplicates(subset=['Clean_Key'], keep='first')\n",
        "\n",
        "    # Indexing\n",
        "    ref_contents = df_ref_clean['Clean_Key'].tolist()\n",
        "    ref_ids = df_ref_clean['FORM_ID_KONTRAK_PAYUNG'].tolist()\n",
        "    ref_map = dict(zip(ref_contents, ref_ids))\n",
        "\n",
        "    # --- TARGET PROCESSING ---\n",
        "    col_tgt_id = 'FORM_ID (KontrakPayung)'\n",
        "    tgt_indices = df_tgt[df_tgt[col_tgt_id].apply(lambda x: pd.isna(x) or not str(x).replace('.','').isdigit())].index\n",
        "\n",
        "    print(f\"\\nüöÄ Memulai Pencocokan untuk {len(tgt_indices)} baris data...\")\n",
        "\n",
        "    memo_cache = {}\n",
        "    stats = {'AUTO': 0, 'REVIEW': 0, 'EXACT': 0}\n",
        "\n",
        "    # Progress Bar Loop\n",
        "    for idx in tqdm(tgt_indices, desc=\"Processing\", unit=\"row\"):\n",
        "        raw_txt = str(df_tgt.at[idx, 'ItemPekerjaan'])\n",
        "        parsed_txt = get_content_parser(raw_txt)\n",
        "        clean_txt = preprocess(parsed_txt)\n",
        "\n",
        "        if clean_txt in memo_cache:\n",
        "            res = memo_cache[clean_txt]\n",
        "        else:\n",
        "            if clean_txt in ref_map:\n",
        "                res = (ref_map[clean_txt], 100, \"PERFECT\", \"Exact Match\")\n",
        "                stats['EXACT'] += 1\n",
        "            else:\n",
        "                match = process.extractOne(clean_txt, ref_contents, scorer=fuzz.token_set_ratio)\n",
        "                cand, score = match[0], match[1]\n",
        "\n",
        "                status = \"AUTO\" if score >= 85 else \"REVIEW\"\n",
        "                res = (ref_map.get(cand), score, status, f\"Matched: {cand}\")\n",
        "\n",
        "                if status == \"AUTO\": stats['AUTO'] += 1\n",
        "                else: stats['REVIEW'] += 1\n",
        "\n",
        "            memo_cache[clean_txt] = res\n",
        "\n",
        "        mid, sc, st, note = res\n",
        "        df_tgt.at[idx, col_tgt_id] = mid\n",
        "        df_tgt.at[idx, 'STATUS_MATCH'] = st\n",
        "        df_tgt.at[idx, 'MATCH_SCORE'] = sc\n",
        "        if st == \"REVIEW\":\n",
        "            df_tgt.at[idx, 'SARAN_MATCH'] = f\"{note} (ID: {mid})\"\n",
        "\n",
        "    # --- REPORT & SAVE ---\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\n‚úÖ PROSES SELESAI dalam {str(timedelta(seconds=int(elapsed)))}\")\n",
        "    print(\"üìä Statistik Akhir:\")\n",
        "    print(f\"   - Exact Matches (100%): {stats['EXACT']}\")\n",
        "    print(f\"   - Auto Fill (>85%): {stats['AUTO']}\")\n",
        "    print(f\"   - Review Needed (<85%): {stats['REVIEW']}\")\n",
        "\n",
        "    print(f\"\\nüíæ Menyimpan hasil ke '{OUTPUT_FILE}'...\")\n",
        "    df_tgt.to_excel(OUTPUT_FILE, index=False)\n",
        "\n",
        "    print(\"üì• Mengunduh file...\")\n",
        "    files.download(OUTPUT_FILE)\n",
        "    if not duplicates.empty:\n",
        "        files.download(LOG_FILE)\n",
        "\n",
        "run_monitoring_engine()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "NAZo2hGj05Pa",
        "outputId": "bf4f2c82-3c51-44a7-aec9-3a426173e4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä STARTING V14 FULL MONITORING SYSTEM...\n",
            "üìÇ Membaca file Excel...\n",
            "   - Target Rows: 57412\n",
            "   - Ref Rows: 3269\n",
            "\n",
            "üîç Mengaudit Data Referensi...\n",
            "‚ö†Ô∏è  Ditemukan 137 duplikat dalam Referensi.\n",
            "üìù Menyimpan log duplikat ke 'Log_Duplikat_Dihapus.csv'...\n",
            "\n",
            "üöÄ Memulai Pencocokan untuk 20112 baris data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20112/20112 [02:04<00:00, 161.67row/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ PROSES SELESAI dalam 0:02:11\n",
            "üìä Statistik Akhir:\n",
            "   - Exact Matches (100%): 12\n",
            "   - Auto Fill (>85%): 1697\n",
            "   - Review Needed (<85%): 6590\n",
            "\n",
            "üíæ Menyimpan hasil ke 'Hasil_Mapping_V14_Monitoring.xlsx'...\n",
            "üì• Mengunduh file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c9a6df85-a488-4c7d-af94-33d804cd132d\", \"Hasil_Mapping_V14_Monitoring.xlsx\", 3235034)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c2acb12b-9c23-4220-8fec-7f89ceb5e583\", \"Log_Duplikat_Dihapus.csv\", 30898)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 1. INSTALASI ENGINE BARU (WAJIB RUN)\n",
        "# ==========================================\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Install RapidFuzz (Jauh lebih cepat dari TheFuzz)\n",
        "try:\n",
        "    import rapidfuzz\n",
        "    print(\"‚úÖ Engine 'rapidfuzz' siap.\")\n",
        "except ImportError:\n",
        "    print(\"üöÄ Menginstall engine Turbo 'rapidfuzz'...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"rapidfuzz\"])\n",
        "    print(\"‚úÖ Instalasi selesai.\")\n",
        "    import rapidfuzz\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rapidfuzz import process, fuzz, utils\n",
        "import re\n",
        "import time\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# ==========================================\n",
        "# 2. SETUP CONFIG\n",
        "# ==========================================\n",
        "FILENAME = '2. ItemTambahanKontrakPayung 2019-2022 Hasil Mapping.xlsx'\n",
        "OUTPUT_FILE = 'Hasil_Mapping_V9_Turbo.xlsx'\n",
        "\n",
        "# Auto-Upload jika file tidak ada\n",
        "if not os.path.exists(FILENAME):\n",
        "    print(f\"\\n‚ö†Ô∏è File '{FILENAME}' tidak ditemukan.\")\n",
        "    print(\"üìÇ Silakan upload file Excel Anda...\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        FILENAME = list(uploaded.keys())[0]\n",
        "    else:\n",
        "        sys.exit(\"‚ùå Upload dibatalkan.\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. FUNGSI OPTIMASI\n",
        "# ==========================================\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isna(text): return \"\"\n",
        "    # RapidFuzz punya utilitas preprocessing sendiri yang sangat cepat\n",
        "    # Tapi kita lakukan basic cleaning untuk konsistensi\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s\\->]', ' ', text)\n",
        "    return \" \".join(text.split())\n",
        "\n",
        "def get_leaf_node(text):\n",
        "    if '>' in text:\n",
        "        return text.split('>')[-1].strip()\n",
        "    return text\n",
        "\n",
        "def is_target(val):\n",
        "    # Cek apakah cell ini perlu diisi (Bukan angka)\n",
        "    if pd.isna(val): return True\n",
        "    try:\n",
        "        float(val)\n",
        "        return False\n",
        "    except ValueError:\n",
        "        return True\n",
        "\n",
        "# Cache Global untuk menyimpan hasil perhitungan\n",
        "# Format: { 'teks_bersih': (match_id, score, source, status, action) }\n",
        "memoization_cache = {}\n",
        "\n",
        "# ==========================================\n",
        "# 4. ENGINE V9.0 (TURBO)\n",
        "# ==========================================\n",
        "\n",
        "def run_turbo_mapping():\n",
        "    print(f\"\\nüèéÔ∏è MEMULAI V9.0 TURBO ENGINE...\")\n",
        "    t_start_total = time.time()\n",
        "\n",
        "    # --- LOAD DATA ---\n",
        "    print(\"üìÇ Membaca Excel...\")\n",
        "    xl = pd.ExcelFile(FILENAME)\n",
        "\n",
        "    # Auto-detect sheets\n",
        "    sheet_tgt = next((s for s in xl.sheet_names if 'ItemTambahan' in s), xl.sheet_names[0])\n",
        "    sheet_ref = next((s for s in xl.sheet_names if 'ItemKontrak' in s and s != sheet_tgt),\n",
        "                     xl.sheet_names[1] if len(xl.sheet_names) > 1 else None)\n",
        "\n",
        "    df_target = xl.parse(sheet_tgt)\n",
        "    df_ref = xl.parse(sheet_ref)\n",
        "\n",
        "    # --- INDEXING REFERENSI ---\n",
        "    print(\"‚öôÔ∏è Membangun Index Referensi Cepat...\")\n",
        "\n",
        "    # Preprocess Referensi\n",
        "    df_ref['clean_item'] = df_ref['ItemPekerjaan'].apply(preprocess_text)\n",
        "    if 'Satuan' in df_ref.columns:\n",
        "        df_ref['clean_satuan'] = df_ref['Satuan'].apply(preprocess_text)\n",
        "        df_ref_clean = df_ref.drop_duplicates(subset=['clean_item', 'clean_satuan'])\n",
        "    else:\n",
        "        df_ref_clean = df_ref.drop_duplicates(subset=['clean_item'])\n",
        "\n",
        "    df_ref_clean = df_ref_clean[df_ref_clean['clean_item'] != \"\"]\n",
        "\n",
        "    # Optimasi: List referensi untuk RapidFuzz\n",
        "    ref_names = df_ref_clean['clean_item'].tolist()\n",
        "    ref_ids = df_ref_clean['FORM_ID_KONTRAK_PAYUNG'].tolist()\n",
        "\n",
        "    # Mapping nama ke ID (untuk lookup cepat)\n",
        "    # Kita butuh map yang handle duplikat nama (jika ada) - ambil yang pertama\n",
        "    ref_map = dict(zip(ref_names, ref_ids))\n",
        "\n",
        "    # Set Keywords untuk validasi\n",
        "    valid_keywords = set()\n",
        "    for name in ref_names:\n",
        "        valid_keywords.update([w for w in name.split() if len(w) > 2])\n",
        "\n",
        "    print(f\"   Referensi Valid: {len(ref_names)} items\")\n",
        "\n",
        "    # --- FILTER TARGET ---\n",
        "    col_tgt_id = 'FORM_ID (KontrakPayung)'\n",
        "    target_indices = df_target[df_target[col_tgt_id].apply(is_target)].index\n",
        "    print(f\"   Target Kosong: {len(target_indices)} baris\")\n",
        "\n",
        "    # Siapkan Kolom\n",
        "    for c in ['STATUS_MATCH', 'MATCH_SCORE', 'MATCH_SOURCE', 'SARAN_MATCH']:\n",
        "        if c not in df_target.columns: df_target[c] = \"\"\n",
        "\n",
        "    # --- MAIN LOOP WITH CACHING ---\n",
        "    print(\"\\n‚ö° PROCESSING (CACHE ENABLED)...\")\n",
        "\n",
        "    count_processed = 0\n",
        "    cache_hits = 0\n",
        "\n",
        "    # Konversi ke list untuk iterasi cepat\n",
        "    tgt_items = df_target.loc[target_indices, 'ItemPekerjaan'].astype(str).tolist()\n",
        "\n",
        "    results = [] # Simpan hasil sementara\n",
        "\n",
        "    for i, raw_text in enumerate(tgt_items):\n",
        "        if i % 500 == 0:\n",
        "            print(f\"   Progress: {i}/{len(tgt_items)} | Cache Hits: {cache_hits}...\", end='\\r')\n",
        "\n",
        "        clean_txt = preprocess_text(raw_text)\n",
        "        if not clean_txt:\n",
        "            results.append(None)\n",
        "            continue\n",
        "\n",
        "        # 1. CEK CACHE (Ini kunci kecepatannya!)\n",
        "        if clean_txt in memoization_cache:\n",
        "            cache_hits += 1\n",
        "            results.append(memoization_cache[clean_txt])\n",
        "            continue\n",
        "\n",
        "        # 2. LOGIKA MATCHING (Jika belum ada di cache)\n",
        "        best_cand = None\n",
        "        best_score = 0\n",
        "        match_src = \"\"\n",
        "\n",
        "        # A. Exact Match\n",
        "        if clean_txt in ref_map:\n",
        "            best_cand, best_score, match_src = clean_txt, 100, \"Exact\"\n",
        "        else:\n",
        "            # B. Fuzzy Full (Pakai RapidFuzz)\n",
        "            # scorer=token_set_ratio sangat bagus untuk kata yang tertukar\n",
        "            res = process.extractOne(clean_txt, ref_names, scorer=fuzz.token_set_ratio)\n",
        "            if res:\n",
        "                best_cand, best_score = res[0], res[1]\n",
        "                match_src = \"Full String\"\n",
        "\n",
        "                # C. Smart Hierarchy Check\n",
        "                if best_score < 85 and '>' in raw_text:\n",
        "                    leaf_txt = preprocess_text(get_leaf_node(raw_text))\n",
        "                    # Cek Exact Leaf\n",
        "                    if leaf_txt in ref_map:\n",
        "                        best_cand, best_score, match_src = leaf_txt, 95, \"Leaf Exact\"\n",
        "                    else:\n",
        "                        # Fuzzy Leaf\n",
        "                        res_leaf = process.extractOne(leaf_txt, ref_names, scorer=fuzz.token_set_ratio)\n",
        "                        if res_leaf and res_leaf[1] > best_score + 5:\n",
        "                            best_cand, best_score, match_src = res_leaf[0], res_leaf[1], \"Leaf Fuzzy\"\n",
        "\n",
        "        # 3. VALIDASI & DECISION\n",
        "        matched_id = ref_map.get(best_cand, \"\")\n",
        "\n",
        "        # Keyword Common Core check\n",
        "        cand_tokens = set(str(best_cand).split())\n",
        "        tgt_tokens = set(clean_txt.split())\n",
        "        if \"Leaf\" in match_src:\n",
        "            tgt_tokens = set(preprocess_text(get_leaf_node(raw_text)).split())\n",
        "\n",
        "        common = len(cand_tokens.intersection(tgt_tokens).intersection(valid_keywords))\n",
        "\n",
        "        # Tiers\n",
        "        status, action, saran = \"\", \"SKIP\", \"\"\n",
        "\n",
        "        if best_score >= 90:\n",
        "            status, action = \"PERFECT\", \"AUTO\"\n",
        "        elif best_score >= 80 and common >= 1:\n",
        "            status, action = \"HIGH\", \"AUTO\"\n",
        "        elif best_score >= 60 and common >= 1:\n",
        "            status, action = \"GOOD/FAIR\", \"REVIEW\"\n",
        "            saran = f\"{best_cand} (ID:{matched_id})\"\n",
        "        elif best_score >= 50:\n",
        "            status, action = \"FORCED\", \"REVIEW\"\n",
        "            saran = f\"{best_cand} (ID:{matched_id})\"\n",
        "        else:\n",
        "            status, action = \"LAST_RESORT\", \"REVIEW\"\n",
        "            saran = f\"{best_cand} (ID:{matched_id})\"\n",
        "\n",
        "        # Simpan ke Cache\n",
        "        result_tuple = (matched_id, best_score, match_src, status, action, saran)\n",
        "        memoization_cache[clean_txt] = result_tuple\n",
        "        results.append(result_tuple)\n",
        "\n",
        "    # --- UPDATE DATAFRAME ---\n",
        "    print(\"\\nüíæ Menyimpan hasil ke DataFrame...\")\n",
        "\n",
        "    # Update bulk untuk performa\n",
        "    for idx, res in zip(target_indices, results):\n",
        "        if res:\n",
        "            matched_id, score, src, status, act, saran = res\n",
        "\n",
        "            df_target.at[idx, 'MATCH_SCORE'] = score\n",
        "            df_target.at[idx, 'MATCH_SOURCE'] = src\n",
        "            df_target.at[idx, 'STATUS_MATCH'] = status\n",
        "\n",
        "            if act == \"AUTO\":\n",
        "                df_target.at[idx, col_tgt_id] = matched_id\n",
        "            elif act == \"REVIEW\":\n",
        "                # Kita isi ID juga agar 'tidak kosong' sesuai request, tapi tandai REVIEW\n",
        "                df_target.at[idx, col_tgt_id] = matched_id\n",
        "                df_target.at[idx, 'SARAN_MATCH'] = saran\n",
        "\n",
        "    # --- FINALIZE ---\n",
        "    print(f\"‚úÖ SELESAI! Waktu Total: {time.time() - t_start_total:.1f} detik\")\n",
        "    print(f\"   - Cache Efficiency: {cache_hits}/{len(tgt_items)} baris diambil dari memori.\")\n",
        "\n",
        "    df_target.to_excel(OUTPUT_FILE, index=False)\n",
        "    print(f\"üìÇ File Output: {OUTPUT_FILE}\")\n",
        "\n",
        "run_turbo_mapping()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFDWjK4gobHI",
        "outputId": "e70caf48-16f5-4b72-f864-3db30d23cbea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Engine 'rapidfuzz' siap.\n",
            "\n",
            "üèéÔ∏è MEMULAI V9.0 TURBO ENGINE...\n",
            "üìÇ Membaca Excel...\n",
            "‚öôÔ∏è Membangun Index Referensi Cepat...\n",
            "   Referensi Valid: 3247 items\n",
            "   Target Kosong: 20112 baris\n",
            "\n",
            "‚ö° PROCESSING (CACHE ENABLED)...\n",
            "\n",
            "üíæ Menyimpan hasil ke DataFrame...\n",
            "‚úÖ SELESAI! Waktu Total: 285.3 detik\n",
            "   - Cache Efficiency: 10825/20112 baris diambil dari memori.\n",
            "üìÇ File Output: Hasil_Mapping_V9_Turbo.xlsx\n"
          ]
        }
      ]
    }
  ]
}